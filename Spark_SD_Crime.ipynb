{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_SD_Crime.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTLrNsJhKVaOyR3JJC9SlV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tingyiwu714/san-diego-crime-analysis/blob/master/Spark_SD_Crime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in8la4g941ZM",
        "colab_type": "text"
      },
      "source": [
        "# San Diego Crime Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F_TCl_4cOBl",
        "colab_type": "text"
      },
      "source": [
        "Analysis of crimes in San Diego County from 2007 to 2017 using Apache Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR5bk_E6WGMA",
        "colab_type": "text"
      },
      "source": [
        "## Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dxW-rKfWTYI",
        "colab_type": "text"
      },
      "source": [
        "1. Data Exploration\n",
        "2. Data Visualization\n",
        "3. Conclusion\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYHGmFht6_Xz",
        "colab_type": "text"
      },
      "source": [
        "## 0: Setup and Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG33CTQCV-Rb",
        "colab_type": "text"
      },
      "source": [
        "### 0.1 Set up Google Drive environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKF867kxKqVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Spark, Java and findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar -xvf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "# Initilize pyspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "# Start spark session\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkNFGmB1sZmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install geocoding library \n",
        "!pip install geopy\n",
        "\n",
        "# Install folium\n",
        "!pip install folium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6KQbHRiTKHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from functools import reduce\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql import Row\n",
        "\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "import folium\n",
        "from folium.plugins import HeatMap, MarkerCluster\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_Wv6WrWIWp",
        "colab_type": "text"
      },
      "source": [
        "### 0.2 Load datasets into Spark DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOCtLdttqM4u",
        "colab_type": "text"
      },
      "source": [
        "The data was adapted from the San Diego Regional Data Library. It includes all valid crimes reported to the San Diego County Police Departments from 2007 to 2017. \n",
        "\n",
        "The data is separated in years and in different format.\n",
        "*   Datasets of 2007 to 2011 are in csv format ([link](https://data.sandiegodata.org/dataset/raw-san-diego-county-crime-incidents-2007-2013/))\n",
        "*   Datasets of 2012 to 2017 are in xlsx format  ([link](https://data.sandiegodata.org/dataset/raw-san-diego-county-crime-incidents-2012-2017/))\n",
        "\n",
        "The data will be loaded in Spark DataFrames from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPFWhiAATmgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load crime data between 2007 to 2011\n",
        "# file_id = ['1GynC_phtJr_ycck_FwP6U_1G4-wGjjrb']\n",
        "file_id = ['16GBta4t4zAWO0yr7w7dLDyo7Ji34zzWf']\n",
        "# file_id = ['16GBta4t4zAWO0yr7w7dLDyo7Ji34zzWf',\n",
        "#            '1EblPEoGj4x8hvxLzjsDZh-IKeYhELE18',\n",
        "#            '1tbURDD5QDeAgaHgGvZxIBIrkmQIxFPeh',\n",
        "#            '1WuFB52qSr-dnB5--u5jYwog5Uno12tEK',\n",
        "#            '1QdadT4p1O-FJdjfFlSkSI2Y9dFN-cKdq']\n",
        "mySchema = StructType([StructField(\"activityType\", StringType(), True),\n",
        "                       StructField(\"AGENCY\", StringType(), True),\n",
        "                       StructField(\"activityDate\", StringType(), True),\n",
        "                       StructField(\"LEGEND\", StringType(), True),\n",
        "                       StructField(\"Charge_Description\", StringType(), True),\n",
        "                       StructField(\"BLOCK_ADDRESS\", StringType(), True),\n",
        "                       StructField(\"City_Name\", StringType(), True),\n",
        "                       StructField(\"ZipCode\", StringType(), True)])\n",
        "sdfs = []\n",
        "for id in file_id:\n",
        "  link = 'https://drive.google.com/uc?export=download&id={FILE_ID}'\n",
        "  url = link.format(FILE_ID=id)\n",
        "  pdf = pd.read_csv(url, dtype=str)\n",
        "  spd = spark.createDataFrame(pdf, schema=mySchema)\n",
        "  sdfs.append(spd)\n",
        "df_07to11 = reduce(DataFrame.unionAll, sdfs)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k6RSmjJ__b0l",
        "colab": {}
      },
      "source": [
        "# Load crime data between 2012 to 2017\n",
        "# file_id = ['12VYPF8HeJH1CpDfsM3fbn2S77KBhD6pv']\n",
        "file_id = ['1TpeuhgB7IHa7IDupjkSoY_CdLHQCdIhd']\n",
        "# file_id = ['1TpeuhgB7IHa7IDupjkSoY_CdLHQCdIhd',\n",
        "#            '1WgMUozlgojzrc3RPREimLrcToY1yoRaA',\n",
        "#            '1d05-6gtJYEanI6W-9NhteVEzL6mdpXe_',\n",
        "#            '1VdAikAd1LRkh7Z81bVv61R_A4RUespTf',\n",
        "#            '159AY4OxMvX-XF00FqFQW4KPy1aJOWjMJ',\n",
        "#            '18A3yryRU2q873W149H653jl_UgxWsM_-']\n",
        "mySchema = StructType([StructField(\"reportingYear\", StringType(), True),\n",
        "                       StructField(\"reportingMonth\", StringType(), True),\n",
        "                       StructField(\"agency\", StringType(), True),\n",
        "                       StructField(\"activityStatus\", StringType(), True),\n",
        "                       StructField(\"activitydate\", StringType(), True),\n",
        "                       StructField(\"numberActualReported\", StringType(), True),\n",
        "                       StructField(\"BLOCK_ADDRESS\", StringType(), True),\n",
        "                       StructField(\"city\", StringType(), True),\n",
        "                       StructField(\"zipCode\", StringType(), True),\n",
        "                       StructField(\"censusTract\", StringType(), True),\n",
        "                       StructField(\"censusBlock\", StringType(), True),\n",
        "                       StructField(\"CrimeCategory\", StringType(), True),\n",
        "                       StructField(\"CrimeDescription\", StringType(), True)])\n",
        "sdfs = []\n",
        "for id in file_id:\n",
        "  link = 'https://drive.google.com/uc?export=download&id={FILE_ID}'\n",
        "  url = link.format(FILE_ID=id)\n",
        "  pdf = pd.read_excel(url, dtype=str)\n",
        "  spd = spark.createDataFrame(pdf, schema=mySchema)\n",
        "  sdfs.append(spd)\n",
        "df_12to17 = reduce(DataFrame.unionAll, sdfs)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPyFFMKdQruY",
        "colab_type": "text"
      },
      "source": [
        "## 1: Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NYBPMTxfUaJ",
        "colab_type": "text"
      },
      "source": [
        "These crime incident records are not cleaned, processed or geocoded, and they are inconsistent in many ways. In this part, I will do data cleaning and processing including:\n",
        "\n",
        "\n",
        "*   **Merge two datasets** (2007-2011 and 2012-2017): Two datasets have different column name, and the datasets of 2007-2011 have less columns then 2012-2017. \n",
        "*   **Handle missing values**: Delete rows contain null and NaN\n",
        "*   **Parsing dates**: Convert data to timestamp. There are 3 different time formats in the data\n",
        "*   **Handle inconsistent data**: Crime categories are organized differently between 2007-2011 and 2012-2017 data.\n",
        "*   **Geocoding**: Fix typo of the address and convert to geographic coordinates\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-EBdMTfQ50a",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Understand Raw Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9iEFX8Bo8Y5",
        "colab_type": "text"
      },
      "source": [
        "Total of 2M rows of individual crime incidents. It includes the detail of each incident."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xblWZTSLSnZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "3c7ca1ab-f875-49ea-84c2-0a0137299132"
      },
      "source": [
        "print(\"Number of rows: \", df_07to11.count())\n",
        "print(\"Number of cols: \", len(df_07to11.columns))\n",
        "df_07to11.show(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows:  5\n",
            "Number of cols:  8\n",
            "+------------+--------------------+--------------------+-------------+------------------+--------------------+------------+-------+\n",
            "|activityType|              AGENCY|        activityDate|       LEGEND|Charge_Description|       BLOCK_ADDRESS|   City_Name|ZipCode|\n",
            "+------------+--------------------+--------------------+-------------+------------------+--------------------+------------+-------+\n",
            "|  CRIME CASE| Carlsbad Police, CA|       1/1/2008 0:00|THEFT/LARCENY|       PETTY THEFT|2500  BLOCK ORION...|    CARLSBAD|  92008|\n",
            "|  CRIME CASE|Chula Vista Polic...|       1/1/2008 0:00|        FRAUD|             FRAUD|1200  BLOCK AGUIR...| CHULA VISTA|  91910|\n",
            "|  CRIME CASE|Chula Vista Polic...|       1/1/2008 0:00|        FRAUD|             FRAUD|2400  BLOCK GOLFC...| CHULA VISTA|  91915|\n",
            "|  CRIME CASE|Chula Vista Polic...|       1/1/2008 0:00|        FRAUD|             FRAUD| 400  BLOCK J STREET| CHULA VISTA|  91910|\n",
            "|  CRIME CASE|San Diego Police, CA|Dec 31, 2008 11:5...|        FRAUD|             FRAUD|200  BLOCK 10TH S...|NON-REGIONAL|    NaN|\n",
            "+------------+--------------------+--------------------+-------------+------------------+--------------------+------------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0AkzqeSSpSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "ec54b81c-290d-4154-e8a4-d3b11488e5b4"
      },
      "source": [
        "print(\"Number of rows: \", df_12to17.count())\n",
        "print(\"Number of cols: \", len(df_12to17.columns))\n",
        "df_12to17.show(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows:  5\n",
            "Number of cols:  13\n",
            "+-------------+--------------+--------+--------------------+-------------------+--------------------+--------------------+--------+-------+-----------+-----------+-------------+------------------+\n",
            "|reportingYear|reportingMonth|  agency|      activityStatus|       activitydate|numberActualReported|       BLOCK_ADDRESS|    city|zipCode|censusTract|censusBlock|CrimeCategory|  CrimeDescription|\n",
            "+-------------+--------------+--------+--------------------+-------------------+--------------------+--------------------+--------+-------+-----------+-----------+-------------+------------------+\n",
            "|         2016|             1|CARLSBAD|     OPEN - WORKABLE|Aug  1 2015 12:00PM|                   1|2800  BLOCK WINTH...|CARLSBAD|  92010|   '019803'|    '03004'|Part II Crime|        SEX CRIMES|\n",
            "|         2016|             1|CARLSBAD|     OPEN - WORKABLE|Aug 31 2015 12:00PM|                   1|6600  BLOCK HIDDE...|CARLSBAD|  92011|   '017811'|    '02003'|         Rape|              RAPE|\n",
            "|         2016|             1|CARLSBAD|CLEARED - EXCEPTI...|Dec  1 2015 10:00AM|                   1|4400  BLOCK TRIES...|CARLSBAD|  92010|   '019804'|    '01008'|Part II Crime|OTHER NON-CRIMINAL|\n",
            "|         2016|             1|CARLSBAD|     OPEN - WORKABLE|Dec  4 2015 12:00PM|                   1|    0  BLOCK UNKNOWN| UNKNOWN|    NaN|        NaN|        NaN|Part II Crime|             FRAUD|\n",
            "|         2016|             1|CARLSBAD|     OPEN - WORKABLE|Dec  6 2015  9:00AM|                   1|3000  BLOCK HARDI...|CARLSBAD|  92008|   '017900'|    '02013'|Part II Crime|MALICIOUS MISCHIEF|\n",
            "+-------------+--------------+--------+--------------------+-------------------+--------------------+--------------------+--------+-------+-----------+-----------+-------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJHTlvwYRL1S",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Data Cleaning and Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md5XJyK9Y8Wr",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.1 Merge two DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMZRB04i-dYO",
        "colab_type": "text"
      },
      "source": [
        "Here, I will only keep the columns contain useful information including occurred date, description and location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xE5LrfAZB4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename columns\n",
        "df_07to11 = df_07to11.withColumnRenamed('activityDate', 'date')\\\n",
        "                     .withColumnRenamed('LEGEND', 'category')\\\n",
        "                     .withColumnRenamed('Charge_Description', 'description')\\\n",
        "                     .withColumnRenamed('City_Name', 'city')\n",
        "for col in df_07to11.columns:\n",
        "    df_07to11 = df_07to11.withColumnRenamed(col, col.lower())\n",
        "\n",
        "df_12to17 = df_12to17.withColumnRenamed('activityDate', 'date')\\\n",
        "                     .withColumnRenamed('CrimeCategory', 'category')\\\n",
        "                     .withColumnRenamed('CrimeDescription', 'description')\n",
        "for col in df_12to17.columns:\n",
        "    df_12to17 = df_12to17.withColumnRenamed(col, col.lower())"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g8HhcZYJ5RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Union two dataframes and remove duplicates\n",
        "cols = [\"date\", \"category\", \"description\", \"block_address\", \"city\", \"zipcode\"]\n",
        "df1 = df_07to11.select(cols)\n",
        "df2 = df_12to17.select(cols)\n",
        "df = df1.union(df2).distinct()"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqu4v9l5xw6Q",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.2 Missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV1J1MPz2TKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "be0154a5-9d4c-43ba-c58e-47279b913774"
      },
      "source": [
        "# Count missing values of each columns\n",
        "missing = df.select([count(when(isnan(c), c)).alias(c) for c in df.columns])\n",
        "print(\"Number of missing data per column:\")\n",
        "missing.show()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of missing data per column:\n",
            "+----+--------+-----------+-------------+----+-------+\n",
            "|date|category|description|block_address|city|zipcode|\n",
            "+----+--------+-----------+-------------+----+-------+\n",
            "|   0|       0|          0|         1638|3832|  22962|\n",
            "+----+--------+-----------+-------------+----+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcttYDpj_FYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the rows with all NaN values\n",
        "# Drop the rows with all location columns are NaN\n",
        "df = df.filter(df.date != 'NaN')\\\n",
        "       .filter((df.block_address != 'NaN') & (df.city != 'NaN') & (df.zipcode != 'NaN'))"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRug4epDPKUf",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.3 Parsing dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Gh_iqDRbRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove extra space\n",
        "df = df.withColumn('date', regexp_replace('date', '  ', ' '))"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngcg3dnDPIzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert \"date\" column to datetime\n",
        "from pyspark.sql.functions import coalesce, col, to_date, to_timestamp\n",
        "def my_to_date(col, frmts=(\"MMM d, y H:m:s a\", \"M/d/y H:m\", \"MMM d y H:ma\")):\n",
        "  return coalesce(*[to_timestamp(col, i) for i in frmts])\n",
        "\n",
        "df = df.withColumn(\"date\", my_to_date(df.date))"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPoC1KkdPaFR",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.4 Inconsistent data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLABhfBzWxTP",
        "colab_type": "text"
      },
      "source": [
        "Based on Uniform Crime Reporting (UCR), crimes are divided into two major groups: Part I crimes and Part II crimes. Part I crimes are broken into two categories: violent and property crimes. Part II crimes are all other crimes outside of Part I crimes.\n",
        "\n",
        "\n",
        "\n",
        "*   Part I crime\n",
        "    * Violent crime: homicide, rape, robbery, aggravated assault\n",
        "    * Property crime: burglary, larceny-thef, motor vehicle theft, arson\n",
        "\n",
        "*   Part I crime: simple assault, drug, fraud, sex offense, DUI, etc.\n",
        "\n",
        "Here, I'll categorize the crime category follow the UCR guideline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs_U7xoVPZXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "8aecebc1-d366-40f9-c48f-8d058564302a"
      },
      "source": [
        "diff = df.select(\"category\").distinct()\n",
        "diff.show()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|            category|\n",
            "+--------------------+\n",
            "|               FRAUD|\n",
            "|       Vehicle Theft|\n",
            "|             WEAPONS|\n",
            "|      Simple Assault|\n",
            "|DRUGS/ALCOHOL VIO...|\n",
            "|     Larceny >= $400|\n",
            "|       THEFT/LARCENY|\n",
            "|               ARSON|\n",
            "|                Rape|\n",
            "|               Arson|\n",
            "|          SEX CRIMES|\n",
            "|             ASSAULT|\n",
            "|                 DUI|\n",
            "| MOTOR VEHICLE THEFT|\n",
            "|    Non Res Burglary|\n",
            "|VEHICLE BREAK-IN/...|\n",
            "|       Part II Crime|\n",
            "|        Res Burglary|\n",
            "|             ROBBERY|\n",
            "|            HOMICIDE|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlzBaexwbpFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.withColumn('category', regexp_replace('category', 'FRAUD', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Vehicle Theft', 'Motor Vehicle Theft'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'WEAPONS', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Simple Assault', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'DRUGS/ALCOHOL VIOLATIONS', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Larceny >= $400', 'Larceny-theft'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'THEFT/LARCENY', 'Larceny-theft'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'SEX CRIMES', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'ASSAULT', 'Aggravated Assault'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'DUI', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Non Res Burglary', 'Burglary'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'VEHICLE BREAK-IN/THEFT', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Res Burglary', 'Burglary'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'HOMICIDE', 'Homicide'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Strong ArmRobbery', 'Robbery'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Murder', 'Homicide'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Armed Robbery', 'Robbery'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'VANDALISM', 'Part II Crime'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Larceny < $400', 'Larceny-theft'))\\\n",
        "        .withColumn('category', initcap('category'))\\\n",
        "        .withColumn('category', regexp_replace('category', 'Part Ii Crime', 'Part II Crime'))"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLtzoA9qVG9I",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.5 Geocoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn8ShofMR8SM",
        "colab_type": "text"
      },
      "source": [
        "Geocoding to convert address into geographic coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjrJUkhr40GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine block address, city, and zipcode to get full address\n",
        "# Remove \"BLOCK\", extra whitespaces, and fix typo\n",
        "# Remove \"0\" from \"01ST\", \"02ND\", \"03RD\", \"04TH\", ...\n",
        "df = df.withColumn('full_address', concat(df.block_address, lit(\", \"), df.city, lit(\", CA \"), df.zipcode))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' BLOCK ', ' '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', '  ', ' '))\\\n",
        "       .withColumn('full_address', trim('full_address'))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' CAM ', ' CAMINO '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' CAMTO ', ' CAMINITO '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' AVNDA ', ' AVENIDA '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' CVENIDA ', ' AVENIDA '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' VIA ', ' VÃA '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' TRZA ', ' TERRAZA '))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' CR DRIVE', ' CIRCLE'))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', ' MC ', ' MC'))\\\n",
        "       .withColumn('full_address', regexp_replace('full_address', '(\\s)(0)(\\d(ST|ND|RD|TH)\\s)', '$1$3'))"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qiIdljNqjs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pd = df.toPandas()\n",
        "df_pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "561B31-Asfb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def geocode_my_address(addr):\n",
        "  try:\n",
        "    x = geolocator.geocode(addr)\n",
        "    lon_lat = x.longitude, x.latitude\n",
        "    return lon_lat\n",
        "  except:\n",
        "    print(\"problem with address:\", addr)\n",
        "    lon_lat = None, None\n",
        "    return lon_lat"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3NLFnMp0rnW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "780ac042-a3c6-4777-96f7-7a3ad1ca7209"
      },
      "source": [
        "geolocator = Nominatim(timeout=10, user_agent = \"dlab.berkeley.edu-workshop\")\n",
        "df_pd['longitude'], df_pd['latitude'] = zip(*df_pd['full_address'].apply(lambda x: geocode_my_address(x)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "problem with address: 25000 BARETA STAR RANCH ROAD, RAMONA, CA 92065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3uiq5wrm2ka",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.6 Save the processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdOK5JmlGj1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j79iI6x5E9fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pd.to_csv('/drive/My Drive/Colab Notebooks/data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v58XyZOJRQly",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIFYhINFnkGu",
        "colab_type": "text"
      },
      "source": [
        "Geospatial Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzTKq5NKCWHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a map\n",
        "m = folium.Map(location=[32.817316, -117.043098], tiles='cartodbpositron', zoom_start=10)\n",
        "\n",
        "heat_df = df_pd[['latitude', 'longitude']]\n",
        "heat_df = heat_df.dropna(axis=0, subset=['latitude','longitude'])\n",
        "\n",
        "HeatMap(data=heat_df[['latitude', 'longitude']], radius=10).add_to(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n13rW1h1q9uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a map\n",
        "m = folium.Map(location=[32.817316, -117.043098], tiles='cartodbpositron', zoom_start=10)\n",
        "\n",
        "# HeatMap(data=df_pd[['latitude', 'longitude']], radius=10).add_to(m)\n",
        "\n",
        "df_pd['latitude'] = df_pd['latitude'].astype(float)\n",
        "df_pd['longitude'] = df_pd['longitude'].astype(float)\n",
        "\n",
        "# Filter the DF for rows, then columns, then remove NaNs\n",
        "heat_df = df_pd[['latitude', 'longitude']]\n",
        "heat_df = heat_df.dropna(axis=0, subset=['latitude','longitude'])\n",
        "\n",
        "# List comprehension to make out list of lists\n",
        "heat_data = [[row['latitude'],row['longitude']] for index, row in heat_df.iterrows()]\n",
        "\n",
        "# Plot it on the map\n",
        "HeatMap(heat_data).add_to(m)\n",
        "\n",
        "# Display the map\n",
        "m\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}